\documentclass{report}
\usepackage[brazil]{babel}
\usepackage[utf8]{inputenc}
\usepackage[num]{abntcite} % Carregamos o pacote abntcite com a opção alf, ou seja, citações alfanuméricas
\usepackage{listings}
\usepackage{hyperref}
\usepackage{url}
%\RequirePackage[colorlinks=false,hyperindex,plainpages=false]{hyperref}


\lstset{language=C,
	extendedchars=true,
	inputencoding=utf8,
	showstringspaces=false,
	tabsize=2,
	texcl=true,
	basicstyle=\scriptsize,
	escapechar={\@},
	breaklines=true
}


\title{GRASP Aplicado ao Problema de Balanceamento de Linhas de Produção}
\author{Cristiano Medeiros Dalbem \and Fábio da Fontoura Beltrão \and Lucas Fialho Zawacki\\
\\
\\
\small Otimização Combinatória (INF05010) - Prof. Marcus Ritt\\
\small Instituto de Informática\\[-0.8ex]
\small Universidade Federal do Rio Grande do Sul
}
%\date{}

\begin{document}

\maketitle
\tableofcontents

\chapter{Introdução}

O trabalho final da disciplina de Otimização Combinatória consiste na escolha de
 um problema de otimização e de uma meta-heurística, e o objetivo é implementar
 uma solução para aquele utilizando-se deste. O problema escolhido foi o
 Balanceamento de linhas de produção \cite{salbp}, e a meta-heurística a GRASP \cite{grasp}.

GRASP é um acrônimo para \emph{Greedy Randomized Adaptive Search Procedure},
cujo nome já especifica muito bem a sua filosofia. O objetivo é formular o
programa com uma heurística gulosa, e o procedimento de resolução da
meta-heurística randomizará cada passo com uma das soluções "mais gulosas".
Para cada solução criada é feita uma Busca Local (Best Fit ou First Fit,
dependendo da implementação), e o processo é repetido por um número
pré-determinado de iterações.

Como objetivos adicionais do trabalho estão a formulação do problema como
um problema de programação inteira/linear, e a execução das soluções
desenvolvidas (GLPK e GRASP) sobre um conjunto de casos de
teste providos pelo professor.

\chapter{Definição do Problema}

Tirada diretamente da definição do trabalho.

Uma linha de produção consiste em uma série de estações de trabalho.
Dado um conjunto de tarefas com restrições de
precedência, temos que atribuir as tarefas às estações, tal que a precedência
é respeitada. Cada tarefa possui um tempo
de execução. O tempo total das tarefas de uma estação define a sua
\emph{carga}, e a carga máxima entre todas as
estações define o \emph{tempo de ciclo}. Formalmente

\begin{description}
 \item [Instância] Um grafo G = (T,P) direcionado acíclico sobre um conjunto de
 tarefas T, o tempo de execução $t_i$ de
cada tarefa $i \in T$, e um número $m$ de estações de trabalho.

 \item [Solução] Uma atribuição $s : T \rightarrow [m]$ das tarefas às
 estações que satisfaz as restrições de
precedência, i.e. para cada $tu \in P$, $s(t) \leq s(u)$.

 \item [Objetivo] Minimizar o tempo de ciclo  $max_{i\in[m]}\sum_{j\in T\mid s(t)=i}t_j$.
\end{description}


\chapter{Programação inteira}

\section{Formulação inteira}

Baseada em \cite{inteiro1} e \cite{inteiro2}.

Seja $T$ o conjunto de tarefas e $M$ o conjunto de máquinas.$x_i_j$ é a variável que indica se a tarefa $i$ foi atribuída à máquina $j$.

\begin{center}
\begin{tabular}{ r l l }
  \textbf{min} & T &\\
  \textbf{s.a} & $ \sum_{i=1}^{n} t_i \cdot x_i_j \leq T $ & $\forall j \in M$\\
& $ \sum_{j=1}^{m} x_i_j = 1 & $\forall i \in T$ \\
& $ \sum_{j=1}^{m} j \cdot x_u_j \leq  \sum_{j=1}^{m} j \cdot x_v_j $ & \forall (u,v) \mid PRECEDE[u,v] = 1 \\
& $ x_i_j \in \mathbb{B} $ & $\forall i \in T$, $\forall j \in M$ \\
	
\end{tabular}
\end{center}

\section{Solução em GLPK}

\begin{lstlisting}
param M;
param N;
param costs{1..N} >= 0;
param prec{1..N, 1..N} >=0;

var cicletime, integer;
var delegate{1..N,1..M} >= 0, binary;


minimize minCicleTime:
	cicletime;

subject to cicleTimeLimit {j in 1..M}:
	(sum {i in 1..N} costs[i]*delegate[i,j]) <= cicletime;

subject to delegateAll {i in 1..N}:
	(sum {j in 1..M} delegate[i,j]) = 1;

subject to respectPrecedences {u in 1..N, v in 1..N}:
	if prec[u,v] == 1 then
		(sum {j in 1..M} j*delegate[u,j]) <= (sum {j in 1..M} j*delegate[v,j]);\n\n");
\end{lstlisting}

\section{Resultados}

\begin{table}[htbp]
 \begin{tabular}{|c|c|c|c|c|}
  \hline
  \textbf{Instância} & \textbf{m} & \textbf{Tempo de execução} & \textbf{Solução Ótima} & \textbf{Solução Obtida} \\
  \hline
  Arcus2 & 27 & 1800* & 5689  & 52039 \\
  \hline
  Arcus2 & 9 & 1800* & 16711 & 32649 \\
  \hline
  Bathol2 & 51 & 1800* & 84 & 1527 \\
  \hline
  Bathol2 & 27 & 1800* & 157 & 1211 \\
  \hline
  Warnecke & 10 & 847 & 155 & 155 \\
  \hline
  Warnecke & 20 & 1800* & 79 & 349 \\
  \hline
  Scholl & 50 & 1800* & 1394 & 57552 \\
  \hline
  Scholl & 38 & 1800* & 1834 & 0 \\
  \hline
  Scholl & 25 & 1800* & 2787 & 32326 \\
  \hline
  Wee-Mag & 20 & 1800* & 77 & 86 \\
  \hline
  Wee-Mag & 30 & 1800* & 56 & 87 \\
  \hline
 \end{tabular}
\end{table}

O testes marcados com * foram interrompidos por alcançarem o limite de tempo imposto.



\chapter{GRASP}

O grupo tentou duas abordagens para a resolver o problema. Uma delas se encaixa
perfeitamente no modelo do GRASP,  a outra nem tanto.

\section{Primeira Abordagem}

\subsection{Construção Gulosa Randomizada}

Para cada tarefa do vetor de tarefas o algoritmo tenta colocá-la, se
isto respeitar o grafo de precedência, em alguma
máquina (se for possível) de maneira que o maior ciclo entre todas as máquinas
seja o menor possível. Cada um desses resultados (o valor de um maior ciclo)
é colocado de maneira ordenada em uma Restricted Candidate List (\emph{RCL})
de tamanho $n$ de tal sorte que se for adicionado um elemento quando ela estiver
cheia o último seja descartado. Após construir a \emph{RCL} retiramos um dos
elementos de maneira aleatória e esta será a máquina na qual deveremos inserir
a tarefa atual.

O processo é repetido para cada uma das tarefas e quando ele acaba teremos
uma atribuição de tarefas $i$ para cada uma das $j$ máquinas.

\section{Busca Local}

Após gerada a solução incial, o algoritmo parte para a busca local.
O objetivo da busca local é ``caminhar'' na
vizinhança da solução, tentando sempre melhorá-la, até não conseguir mais.
Nossa vizinhança é: sabendo que a máquina $m*$
é a máquina que determina o \emph{tempo de ciclo},
retiramos a última tarefa t* atribuida à essa máquina e, para cada
outra máquina m, se for possível atribuir t* à m, isto é feito.
Utilizamos \textit{first improvement} na nossa busca
local, fazedo com que o primero vizinho que melhore a solução seja
escolhido como próxima solução.

Há, porém, o problema de existirem mais que uma máquinas $m*$,
definidoras do \emph{tempo de ciclo}. Tendo isto em vista,
durante a busca local, é considerado que o vizinho melhorou a
solução se o \emph{tempo de ciclo} daquele vizinho for
menor ou se o \emph{tempo de ciclo} do vizinho por igual mas a
quantidade de máquinas m*, que definem este tempo, for
menor. Isto evita que a busca local entre em loop, mas não impede que
eventualmente ela melhore as \emph{cargas} de
todas máquinas m*, melhorando o \emph{tempo de ciclo} global.

\subsection{Resultados e Limitações}

Esta abordagem, principalmente a etapa de construção gulosa, não se mostrou muito
efetiva e os resultados deixaram a desejar. A seguir uma lista com os resultados:

Todos resultados foram obtidos utilizando como limite 100000 iterações.

\begin{table}[htbp]
 \begin{tabular}{|c|c|c|c|c|}
  \hline
  \textbf{Instância} & \textbf{m} & \textbf{Solução Ótima} & \textbf{Solução Obtida} & \% optimalidade \\
  \hline
  Arcus2 & 27 & 5689 & 6125 & 92.88 \\
  \hline
  Arcus2 & 9 & 16711 & 16839 & 99.23 \\
  \hline
  Bathol2 & 51 & 84 & 95 & 88.42 \\
  \hline
  Bathol2 & 27 & 157 & 166 & 94.57 \\
  \hline
  Warnecke & 10 & 155 & 160 & 96.87 \\
  \hline
  Warnecke & 20 & 79 & 85 & 92.94 \\
  \hline
  Scholl & 50 & 1394 & 1506 & 92.56 \\
  \hline
  Scholl & 38 & 1834 & 1938 & 94.63 \\
  \hline
  Scholl & 25 & 2787 & 2862 & 97.37 \\
  \hline
  Wee-Mag & 20 & 77 & 81 & 95.06 \\
  \hline
  Wee-Mag & 30 & 56 & 57 & 98.24 \\
  \hline
 \end{tabular}
\end{table}

O grupo acredita que a ineficácia do algoritmo se deva a uma tendenciosidade do
processo de construção de uma solução. Uma solução em que uma tarefa que denota
muitas dependências fica designada para uma máquina $i$, tal que $i$ é muito
próximo de $n$, acaba sendo bastante ruim. Nesses casos a busca local não
conseguiu explorar o espaço de soluções e acabou com uma solução muito aquém
do desejado.

\section{Segunda Abordagem}

\subsection{Construção Gulosa Randomizada}

Não consideramos esta outra abordagem muito condizente com aquilo que estudamos
sobre GRASP.
Mas devido à natureza do
problema, de longe se mostrou  mais eficiente, ambos em termos de
eficiência computacional (neste caso medindo
somente tempo de execução) como eficiência na qualidade da resposta.

Primeiramente as tarefas são ordenadas topologicamente.
Um problema aqui é que a ordenação é deterministica e gera
sempre o mesmo resultado, e isso é indesejado.
Por isso, sempre que temos mais de uma tarefa possível para ir na
posição $i$ do vetor ordenado, escolhemos randomicamente entre todas,
com isso geramos ordenações topologicas
potencialmente diferentes para cada iteração.

Após, tendo o vetor ordenado, calculamos qual um limite inferior para a
resposta. Isto é feito pegando o valor máximo entre $\frac{\sum_{i\in T}t_i}{m}$ e $max_{i\in T}t_i$. Sendo o primeiro
o valor da distribuição mais uniforme possível, ou seja, soma dos custos de todas tarefas e dividido pelo
número de máquinas. E sendo o segundo o custo da tarefa mais custosa.

Sabendo esse limite inferior, o que é feito é: para cada máquina, eu vou colocando nela as tarefas retiradas, em ordem,
do vetor ordenado topologicamente. Isto é feito enquanto a \emph{carga} da máquina for menor que o limite inferior
calculado. Quando este valor for extrapolado, então é feita a decisão se iremos colocar esta tarefa à mais
(extrapolando o limiar) ou se vamos manter como está (ficando abaixo do limiar). Sempre é tomada a decisão que mais
aproxima a \emph{carga} da máquina do limiar calculado. Resumindo, o que ele faz é tentar aproximar a \emph{carga} de
cada máquina do limite inferior calculado. Como isso não garante a atribuição de todas tarefas, isso é forçado, no fim,
colocando todas tarefas pendentes na última máquina.

\chapter{Resultados}


\chapter{Conclusão}

Os resultados obtidos usando a segunda abordagem se mostraram bastante
satisfatórios, tendo em média uma porcentagem de optimalidade de 94.79. O
GRASP se mostrou como uma heurística muito boa, não só pelos bons resultados,
mas também pela facilidade em se
trabalhar.

De fato, de um modo geral, é bastante fácil entender e implementar o GRASP:
os conceitos envolvidos são bastante simples e ele é composto apenas de duas
funções principais (construção gulosa e busca local), sendo a única
dificuldade dependente do problemo sendo tratado, pois dependendo do mesmo,
formular uma vizinhança ou até mesmo pensar
em um algoritmo guloso que gere a solução inicial pode ser complicado.


\thebibliography{9}

\bibitem{salbp}
	\url{http://www.assembly-line-balancing.de/index.php?content=classview&content2=classview&content3=classviewdlfree&content4=classview&classID=28&type=dl}
	\emph{Homepage for Assembly Line Optimization Research (Assembly Line Balancing and Sequencing)}


\bibitem{grasp}
	\url{http://www.optimization-online.org/DB_FILE/2001/09/371.pdf}
	\title{Greedy randomized adaptive search procedures}
	\author{RESENDE,Mauricio G.C. \and RIBEIRO,Celso C.}
\end{document}

